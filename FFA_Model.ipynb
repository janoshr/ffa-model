{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kCbo6EpgcVUF"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-25 19:06:24.393397: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-25 19:06:24.752533: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-25 19:06:24.752561: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-25 19:06:25.757194: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-25 19:06:25.757354: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-25 19:06:25.757361: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FCWvExeil5A1",
    "outputId": "af01cf44-138b-422b-89ac-8337b52cd9e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18471, 69)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/processed_data.csv')\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2DwofjBGV5Vu",
    "outputId": "def35a07-d36e-4cdb-a49a-1b2113313adb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final labels\n",
    "labels = ['patientState_good', 'patientState_caution', 'patientState_danger']\n",
    "# Section labels\n",
    "section_labels = {\n",
    "    'fever': ['feverState_good', 'feverState_caution', 'feverState_danger'],\n",
    "    'medication': ['medicationState_good', 'medicationState_caution', 'medicationState_danger'],\n",
    "    'hydration': ['hydrationState_good', 'hydrationState_caution', 'hydrationState_danger'],\n",
    "    'respiration': ['respirationState_good', 'respirationState_caution', 'respirationState_danger'],\n",
    "    'skin': ['skinState_good', 'skinState_caution', 'skinState_danger'],\n",
    "    'pulse': ['pulseState_good', 'pulseState_caution', 'pulseState_danger'],\n",
    "    'general': ['generalState_good', 'generalState_caution', 'generalState_danger'],\n",
    "}\n",
    "# Section labels in an array flattened\n",
    "section_labels_arr = [item for val in section_labels.values() for item in val]\n",
    "# All labels\n",
    "all_labels = [*labels, *section_labels_arr]\n",
    "len(all_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SxKJ2bSyYk2B",
    "outputId": "43ed643c-308c-4e14-e0d4-522226ffd95b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generalState_good  generalState_caution  generalState_danger\n",
       "1.0                0.0                   0.0                    10142\n",
       "0.0                1.0                   0.0                     7976\n",
       "                   0.0                   1.0                      353\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[section_labels['general']].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mWqUV0NUat2j",
    "outputId": "be460c23-5c6c-4b7d-ea1d-72254c667811"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11082, 45)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separating to testing and training\n",
    "\n",
    "# Prepare the data: You should split your data into training and test sets.\n",
    "# The training set will be used to train the model and the test set will be used\n",
    "# to evaluate the model's performance.\n",
    "\n",
    "_x, x_test, _y, y_test = train_test_split(\n",
    "    df.drop(columns=all_labels).to_numpy(),\n",
    "    df[labels].to_numpy(),\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    _x,\n",
    "    _y,\n",
    "    test_size=0.25,\n",
    "    train_size=0.75,\n",
    "    random_state=42\n",
    ")\n",
    "x_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "omaRfxh9ozLC",
    "outputId": "1dcde71f-213f-4563-8982-e7315c181532"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[15.6173706445342, 1.0, 38.3, 0.0, 0.0, 0.0, 1.0, 1.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 13.0, 0.0, 0.0, 0.0, 0.0, 68.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(list(x_test[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "UBWlLfXBUf6u"
   },
   "outputs": [],
   "source": [
    "# Preprocess the data: Data preprocessing is an important step, which includes\n",
    "# cleaning and transforming the data. You should normalize the data,\n",
    "# one-hot encode categorical variables, and split the data into features and labels.\n",
    "\n",
    "# TODO: Does KNNImputer create a correlation between training and test split?\n",
    "# If yes do ->\n",
    "# TODO: move KNNImputer here\n",
    "# TODO: move every preprocessing step that would create a connection between train and test split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 45)                2070      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 138       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,208\n",
      "Trainable params: 2,208\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-25 19:07:53.012250: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_COMPAT_NOT_SUPPORTED_ON_DEVICE: forward compatibility was attempted on non supported HW\n",
      "2023-02-25 19:07:53.012276: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: Ghost\n",
      "2023-02-25 19:07:53.012281: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: Ghost\n",
      "2023-02-25 19:07:53.012339: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 470.161.3\n",
      "2023-02-25 19:07:53.012355: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 470.141.3\n",
      "2023-02-25 19:07:53.012360: E tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 470.141.3 does not match DSO version 470.161.3 -- cannot find working devices in this configuration\n",
      "2023-02-25 19:07:53.013310: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Create a baseline model to measure performance\n",
    "b_model = keras.Sequential([\n",
    "    keras.layers.Dense(units=45, activation='tanh', input_shape=(45,)),\n",
    "    keras.layers.Dense(units=3, activation='softmax'),\n",
    "])\n",
    "b_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "b_model.build()\n",
    "b_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "347/347 - 1s - loss: 0.8624 - accuracy: 0.6203 - val_loss: 0.7107 - val_accuracy: 0.7044 - 848ms/epoch - 2ms/step\n",
      "Epoch 2/20\n",
      "347/347 - 0s - loss: 0.6660 - accuracy: 0.7157 - val_loss: 0.6017 - val_accuracy: 0.7664 - 322ms/epoch - 928us/step\n",
      "Epoch 3/20\n",
      "347/347 - 0s - loss: 0.5632 - accuracy: 0.7843 - val_loss: 0.5257 - val_accuracy: 0.7970 - 302ms/epoch - 870us/step\n",
      "Epoch 4/20\n",
      "347/347 - 0s - loss: 0.4993 - accuracy: 0.8064 - val_loss: 0.4723 - val_accuracy: 0.8189 - 300ms/epoch - 865us/step\n",
      "Epoch 5/20\n",
      "347/347 - 0s - loss: 0.4628 - accuracy: 0.8251 - val_loss: 0.4662 - val_accuracy: 0.8078 - 302ms/epoch - 870us/step\n",
      "Epoch 6/20\n",
      "347/347 - 0s - loss: 0.4345 - accuracy: 0.8324 - val_loss: 0.4283 - val_accuracy: 0.8305 - 303ms/epoch - 874us/step\n",
      "Epoch 7/20\n",
      "347/347 - 0s - loss: 0.4151 - accuracy: 0.8384 - val_loss: 0.4070 - val_accuracy: 0.8387 - 311ms/epoch - 897us/step\n",
      "Epoch 8/20\n",
      "347/347 - 0s - loss: 0.3868 - accuracy: 0.8504 - val_loss: 0.3835 - val_accuracy: 0.8519 - 307ms/epoch - 884us/step\n",
      "Epoch 9/20\n",
      "347/347 - 0s - loss: 0.3676 - accuracy: 0.8573 - val_loss: 0.3663 - val_accuracy: 0.8617 - 333ms/epoch - 961us/step\n",
      "Epoch 10/20\n",
      "347/347 - 0s - loss: 0.3504 - accuracy: 0.8628 - val_loss: 0.3666 - val_accuracy: 0.8500 - 321ms/epoch - 924us/step\n",
      "Epoch 11/20\n",
      "347/347 - 0s - loss: 0.3423 - accuracy: 0.8688 - val_loss: 0.3510 - val_accuracy: 0.8668 - 324ms/epoch - 934us/step\n",
      "Epoch 12/20\n",
      "347/347 - 0s - loss: 0.3307 - accuracy: 0.8749 - val_loss: 0.3439 - val_accuracy: 0.8633 - 313ms/epoch - 902us/step\n",
      "Epoch 13/20\n",
      "347/347 - 0s - loss: 0.3211 - accuracy: 0.8794 - val_loss: 0.3409 - val_accuracy: 0.8744 - 320ms/epoch - 922us/step\n",
      "Epoch 14/20\n",
      "347/347 - 0s - loss: 0.3149 - accuracy: 0.8803 - val_loss: 0.3354 - val_accuracy: 0.8725 - 360ms/epoch - 1ms/step\n",
      "Epoch 15/20\n",
      "347/347 - 0s - loss: 0.3048 - accuracy: 0.8859 - val_loss: 0.3306 - val_accuracy: 0.8741 - 312ms/epoch - 898us/step\n",
      "Epoch 16/20\n",
      "347/347 - 0s - loss: 0.3034 - accuracy: 0.8857 - val_loss: 0.3205 - val_accuracy: 0.8795 - 309ms/epoch - 889us/step\n",
      "Epoch 17/20\n",
      "347/347 - 0s - loss: 0.2943 - accuracy: 0.8930 - val_loss: 0.3761 - val_accuracy: 0.8592 - 314ms/epoch - 906us/step\n",
      "Epoch 18/20\n",
      "347/347 - 0s - loss: 0.2935 - accuracy: 0.8910 - val_loss: 0.3127 - val_accuracy: 0.8841 - 317ms/epoch - 914us/step\n",
      "Epoch 19/20\n",
      "347/347 - 0s - loss: 0.2916 - accuracy: 0.8924 - val_loss: 0.3134 - val_accuracy: 0.8855 - 310ms/epoch - 894us/step\n",
      "Epoch 20/20\n",
      "347/347 - 0s - loss: 0.2891 - accuracy: 0.8925 - val_loss: 0.3080 - val_accuracy: 0.8844 - 315ms/epoch - 908us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3ab90d44f0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train baseline model\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "# Early stopping set after 5 epochs\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "b_model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=[stop_early],\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 690us/step - loss: 0.2729 - accuracy: 0.8963\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline</th>\n",
       "      <td>0.272868</td>\n",
       "      <td>0.896346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              loss  accuracy\n",
       "Baseline  0.272868  0.896346"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate_model(model, x_test, y_test):\n",
    "    \"\"\"\n",
    "    evaluate model on test set and show results in dataframe.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : keras model\n",
    "        trained keras model.\n",
    "    X_test : numpy array\n",
    "        Features of holdout set.\n",
    "    y_test : numpy array\n",
    "        Labels of holdout set.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    display_df : DataFrame\n",
    "        Pandas dataframe containing evaluation results.\n",
    "    \"\"\"\n",
    "    eval_dict = model.evaluate(x_test, y_test, return_dict=True)\n",
    "    \n",
    "    display_df = pd.DataFrame([eval_dict.values()], columns=[list(eval_dict.keys())])\n",
    "    \n",
    "    return display_df\n",
    "\n",
    "# Evaluate model on test set and add results to dataframe\n",
    "results = evaluate_model(b_model, x_test, y_test)\n",
    "\n",
    "# Set index to 'Baseline'\n",
    "results.index = ['Baseline']\n",
    "\n",
    "# Display results\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "95i1CiBhU2CL",
    "outputId": "d74a9d05-6a5a-4ef8-f5c8-3c80af36128d"
   },
   "outputs": [],
   "source": [
    "# Define the model: TensorFlow provides a high-level API for building and\n",
    "# training neural network models. You should choose the appropriate model\n",
    "# architecture for your problem and specify the hyperparameters,\n",
    "# such as the number of hidden layers and the number of neurons in each layer.\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='./checkpoints/model_{epoch}',\n",
    "        save_freq='epoch'),\n",
    "    keras.callbacks.TensorBoard(log_dir='./logs')\n",
    "]\n",
    "\n",
    "\n",
    "def build_model(hp):\n",
    "    \"\"\"\n",
    "    Builds model and sets up hyperparameter space to search.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    hp : HyperParameter object\n",
    "        Configures hyperparameters to tune.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    model : keras model\n",
    "        Compiled model with hyperparameters to tune.\n",
    "    \"\"\"\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(\n",
    "            units=hp.Int('units', min_value=32, max_value=512, step=32),\n",
    "            activation=hp.Choice('activation', values=['tanh', 'sigmoid', 'relu']),\n",
    "            input_shape=(45,)),\n",
    "    ])\n",
    "    # Tune the number of hidden layers and units in each.\n",
    "    # Number of hidden layers: 1 - 4\n",
    "    # Number of Units: 32 - 512 with stepsize of 32\n",
    "    num_layers = hp.Int(\"num_layers\", 2, 5)\n",
    "    for i in range(1, num_layers):\n",
    "        with hp.conditional_scope('num_layers', list(range(i+1, 5+1))):\n",
    "            model.add(\n",
    "                keras.layers.Dense(\n",
    "                    units=hp.Int(\"units_\" + str(i), min_value=32, max_value=512, step=32),\n",
    "                    activation=hp.Choice('activation_' + str(i), values=['tanh', 'sigmoid', 'relu']),\n",
    "                )\n",
    "            )\n",
    "            # Tune dropout layer with values from 0 - 0.3 with stepsize of 0.1.\n",
    "            model.add(keras.layers.Dropout(hp.Float(\"dropout_\" + str(i), 0, 0.3, step=0.1)))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(\n",
    "        keras.layers.Dense(3, activation='softmax')\n",
    "    )\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
    "        # optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    model.build()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "vvetSq2eVARF"
   },
   "outputs": [],
   "source": [
    "# Compile the model: You should compile the model by specifying the optimizer,\n",
    "# loss function, and evaluation metrics.\n",
    "import keras_tuner as kt\n",
    "\n",
    "tuner = kt.tuners.Hyperband(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    executions_per_trial=2,\n",
    "    hyperband_iterations=2,\n",
    "    max_epochs=100,\n",
    "    factor=3,\n",
    "    overwrite=False,\n",
    "    directory='tuner3',\n",
    "    project_name=\"hyperband\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 508 Complete [00h 02m 04s]\n",
      "val_loss: 0.2693604677915573\n",
      "\n",
      "Best val_loss So Far: 0.20006748288869858\n",
      "Total elapsed time: 01h 45m 19s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "tuner.search(x_train, y_train, validation_data=(x_val, y_val), epochs=4, callbacks=[stop_early])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in tuner3/hyperband\n",
      "Showing 10 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x7f3ab8f3ff40>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 128\n",
      "activation: relu\n",
      "num_layers: 2\n",
      "units_1: 416\n",
      "activation_1: sigmoid\n",
      "dropout_1: 0.2\n",
      "learning_rate: 0.001\n",
      "tuner/epochs: 100\n",
      "tuner/initial_epoch: 34\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 0228\n",
      "Score: 0.20006748288869858\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 480\n",
      "activation: relu\n",
      "num_layers: 3\n",
      "units_1: 320\n",
      "activation_1: sigmoid\n",
      "dropout_1: 0.1\n",
      "learning_rate: 0.001\n",
      "units_2: 160\n",
      "activation_2: relu\n",
      "dropout_2: 0.0\n",
      "tuner/epochs: 100\n",
      "tuner/initial_epoch: 34\n",
      "tuner/bracket: 3\n",
      "tuner/round: 3\n",
      "tuner/trial_id: 0203\n",
      "Score: 0.2034383863210678\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 384\n",
      "activation: relu\n",
      "num_layers: 5\n",
      "units_1: 448\n",
      "activation_1: sigmoid\n",
      "dropout_1: 0.0\n",
      "learning_rate: 0.001\n",
      "units_2: 128\n",
      "activation_2: sigmoid\n",
      "dropout_2: 0.1\n",
      "units_3: 192\n",
      "activation_3: tanh\n",
      "dropout_3: 0.0\n",
      "units_4: 320\n",
      "activation_4: tanh\n",
      "dropout_4: 0.0\n",
      "tuner/epochs: 100\n",
      "tuner/initial_epoch: 34\n",
      "tuner/bracket: 3\n",
      "tuner/round: 3\n",
      "tuner/trial_id: 0459\n",
      "Score: 0.2053094580769539\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 192\n",
      "activation: relu\n",
      "num_layers: 2\n",
      "units_1: 96\n",
      "activation_1: sigmoid\n",
      "dropout_1: 0.1\n",
      "learning_rate: 0.001\n",
      "tuner/epochs: 100\n",
      "tuner/initial_epoch: 34\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0491\n",
      "Score: 0.20592466741800308\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 320\n",
      "activation: sigmoid\n",
      "num_layers: 3\n",
      "units_1: 224\n",
      "activation_1: relu\n",
      "dropout_1: 0.1\n",
      "learning_rate: 0.001\n",
      "units_2: 448\n",
      "activation_2: tanh\n",
      "dropout_2: 0.0\n",
      "tuner/epochs: 100\n",
      "tuner/initial_epoch: 34\n",
      "tuner/bracket: 4\n",
      "tuner/round: 4\n",
      "tuner/trial_id: 0397\n",
      "Score: 0.21206671744585037\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 128\n",
      "activation: relu\n",
      "num_layers: 2\n",
      "units_1: 224\n",
      "activation_1: sigmoid\n",
      "dropout_1: 0.0\n",
      "learning_rate: 0.001\n",
      "tuner/epochs: 100\n",
      "tuner/initial_epoch: 34\n",
      "tuner/bracket: 3\n",
      "tuner/round: 3\n",
      "tuner/trial_id: 0457\n",
      "Score: 0.21507079899311066\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 480\n",
      "activation: relu\n",
      "num_layers: 4\n",
      "units_1: 256\n",
      "activation_1: sigmoid\n",
      "dropout_1: 0.0\n",
      "learning_rate: 0.001\n",
      "units_2: 32\n",
      "activation_2: tanh\n",
      "dropout_2: 0.2\n",
      "units_3: 64\n",
      "activation_3: sigmoid\n",
      "dropout_3: 0.1\n",
      "tuner/epochs: 34\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 0.21582532674074173\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 480\n",
      "activation: relu\n",
      "num_layers: 4\n",
      "units_1: 256\n",
      "activation_1: sigmoid\n",
      "dropout_1: 0.0\n",
      "learning_rate: 0.001\n",
      "units_2: 32\n",
      "activation_2: tanh\n",
      "dropout_2: 0.2\n",
      "units_3: 64\n",
      "activation_3: sigmoid\n",
      "dropout_3: 0.1\n",
      "tuner/epochs: 100\n",
      "tuner/initial_epoch: 34\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0494\n",
      "Score: 0.21604902297258377\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 480\n",
      "activation: relu\n",
      "num_layers: 3\n",
      "units_1: 320\n",
      "activation_1: sigmoid\n",
      "dropout_1: 0.1\n",
      "learning_rate: 0.001\n",
      "units_2: 160\n",
      "activation_2: relu\n",
      "dropout_2: 0.0\n",
      "tuner/epochs: 34\n",
      "tuner/initial_epoch: 12\n",
      "tuner/bracket: 3\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 0195\n",
      "Score: 0.21760907024145126\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 384\n",
      "activation: relu\n",
      "num_layers: 5\n",
      "units_1: 448\n",
      "activation_1: sigmoid\n",
      "dropout_1: 0.0\n",
      "learning_rate: 0.001\n",
      "units_2: 128\n",
      "activation_2: sigmoid\n",
      "dropout_2: 0.1\n",
      "units_3: 192\n",
      "activation_3: tanh\n",
      "dropout_3: 0.0\n",
      "units_4: 320\n",
      "activation_4: tanh\n",
      "dropout_4: 0.0\n",
      "tuner/epochs: 34\n",
      "tuner/initial_epoch: 12\n",
      "tuner/bracket: 3\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 0451\n",
      "Score: 0.2185087949037552\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tuner.results_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search_space_summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best val_loss So Far: 0.3011022210121155\n",
    "\n",
    "- 5 epochs\n",
    "- 512 units\n",
    "- tanh activation\n",
    "- True 2nd layer\n",
    "- 0.001 learning_rate\n",
    "- 192 units2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline</th>\n",
       "      <td>0.272868</td>\n",
       "      <td>0.896346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              loss  accuracy\n",
       "Baseline  0.272868  0.896346"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model: 0 {'units': 128, 'activation': 'relu', 'num_layers': 2, 'units_1': 416, 'activation_1': 'sigmoid', 'dropout_1': 0.2, 'learning_rate': 0.001, 'tuner/epochs': 100, 'tuner/initial_epoch': 34, 'tuner/bracket': 2, 'tuner/round': 2, 'tuner/trial_id': '0228'}\n",
      "116/116 [==============================] - 0s 855us/step - loss: 0.2273 - accuracy: 0.9212\n",
      "Running model: 1 {'units': 480, 'activation': 'relu', 'num_layers': 3, 'units_1': 320, 'activation_1': 'sigmoid', 'dropout_1': 0.1, 'learning_rate': 0.001, 'units_2': 160, 'activation_2': 'relu', 'dropout_2': 0.0, 'tuner/epochs': 100, 'tuner/initial_epoch': 34, 'tuner/bracket': 3, 'tuner/round': 3, 'tuner/trial_id': '0203'}\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.2460 - accuracy: 0.9202\n",
      "Running model: 2 {'units': 384, 'activation': 'relu', 'num_layers': 5, 'units_1': 448, 'activation_1': 'sigmoid', 'dropout_1': 0.0, 'learning_rate': 0.001, 'units_2': 128, 'activation_2': 'sigmoid', 'dropout_2': 0.1, 'units_3': 192, 'activation_3': 'tanh', 'dropout_3': 0.0, 'units_4': 320, 'activation_4': 'tanh', 'dropout_4': 0.0, 'tuner/epochs': 100, 'tuner/initial_epoch': 34, 'tuner/bracket': 3, 'tuner/round': 3, 'tuner/trial_id': '0459'}\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.2184 - accuracy: 0.9231\n",
      "Running model: 3 {'units': 192, 'activation': 'relu', 'num_layers': 2, 'units_1': 96, 'activation_1': 'sigmoid', 'dropout_1': 0.1, 'learning_rate': 0.001, 'tuner/epochs': 100, 'tuner/initial_epoch': 34, 'tuner/bracket': 1, 'tuner/round': 1, 'tuner/trial_id': '0491'}\n",
      "116/116 [==============================] - 0s 815us/step - loss: 0.2283 - accuracy: 0.9131\n",
      "Running model: 4 {'units': 320, 'activation': 'sigmoid', 'num_layers': 3, 'units_1': 224, 'activation_1': 'relu', 'dropout_1': 0.1, 'learning_rate': 0.001, 'units_2': 448, 'activation_2': 'tanh', 'dropout_2': 0.0, 'tuner/epochs': 100, 'tuner/initial_epoch': 34, 'tuner/bracket': 4, 'tuner/round': 4, 'tuner/trial_id': '0397'}\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.2397 - accuracy: 0.9083\n",
      "Running model: 5 {'units': 128, 'activation': 'relu', 'num_layers': 2, 'units_1': 224, 'activation_1': 'sigmoid', 'dropout_1': 0.0, 'learning_rate': 0.001, 'tuner/epochs': 100, 'tuner/initial_epoch': 34, 'tuner/bracket': 3, 'tuner/round': 3, 'tuner/trial_id': '0457'}\n",
      "116/116 [==============================] - 0s 818us/step - loss: 0.2317 - accuracy: 0.9137\n",
      "Running model: 6 {'units': 480, 'activation': 'relu', 'num_layers': 4, 'units_1': 256, 'activation_1': 'sigmoid', 'dropout_1': 0.0, 'learning_rate': 0.001, 'units_2': 32, 'activation_2': 'tanh', 'dropout_2': 0.2, 'units_3': 64, 'activation_3': 'sigmoid', 'dropout_3': 0.1, 'tuner/epochs': 34, 'tuner/initial_epoch': 0, 'tuner/bracket': 1, 'tuner/round': 0}\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.2126 - accuracy: 0.9237\n",
      "Running model: 7 {'units': 480, 'activation': 'relu', 'num_layers': 4, 'units_1': 256, 'activation_1': 'sigmoid', 'dropout_1': 0.0, 'learning_rate': 0.001, 'units_2': 32, 'activation_2': 'tanh', 'dropout_2': 0.2, 'units_3': 64, 'activation_3': 'sigmoid', 'dropout_3': 0.1, 'tuner/epochs': 100, 'tuner/initial_epoch': 34, 'tuner/bracket': 1, 'tuner/round': 1, 'tuner/trial_id': '0494'}\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.2395 - accuracy: 0.9104\n",
      "Running model: 8 {'units': 480, 'activation': 'relu', 'num_layers': 3, 'units_1': 320, 'activation_1': 'sigmoid', 'dropout_1': 0.1, 'learning_rate': 0.001, 'units_2': 160, 'activation_2': 'relu', 'dropout_2': 0.0, 'tuner/epochs': 34, 'tuner/initial_epoch': 12, 'tuner/bracket': 3, 'tuner/round': 2, 'tuner/trial_id': '0195'}\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.2554 - accuracy: 0.9126\n",
      "Running model: 9 {'units': 384, 'activation': 'relu', 'num_layers': 5, 'units_1': 448, 'activation_1': 'sigmoid', 'dropout_1': 0.0, 'learning_rate': 0.001, 'units_2': 128, 'activation_2': 'sigmoid', 'dropout_2': 0.1, 'units_3': 192, 'activation_3': 'tanh', 'dropout_3': 0.0, 'units_4': 320, 'activation_4': 'tanh', 'dropout_4': 0.0, 'tuner/epochs': 34, 'tuner/initial_epoch': 12, 'tuner/bracket': 3, 'tuner/round': 2, 'tuner/trial_id': '0451'}\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.2455 - accuracy: 0.9066\n"
     ]
    }
   ],
   "source": [
    "params = tuner.get_best_hyperparameters(10)\n",
    "\n",
    "for i, param in enumerate(params):\n",
    "    print('Running model:', i, param.values)\n",
    "    model = tuner.hypermodel.build(param)\n",
    "    model.fit(x_train, y_train, epochs=param.values.get('tuner/epochs'), callbacks=[stop_early], validation_data=(x_val, y_val), verbose=0)\n",
    "    hyper_df = evaluate_model(model, x_test, y_test)\n",
    "    hyper_df.index = [\"Hypertuned-\" + str(i)]\n",
    "    hyper_df['params'] = str(param.values)\n",
    "    # Append results in dataframe\n",
    "    results = pd.concat([results, hyper_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 1: 116/116 [==============================] - 3s 24ms/step - loss: 0.2007 - accuracy: 0.9369\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model: 10\n",
      "116/116 [==============================] - 0s 867us/step - loss: 0.2083 - accuracy: 0.9307\n",
      "Running model: 11\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3100 - accuracy: 0.9050\n",
      "Running model: 12\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.2320 - accuracy: 0.9242\n",
      "Running model: 13\n",
      "116/116 [==============================] - 0s 757us/step - loss: 0.2504 - accuracy: 0.9066\n",
      "Running model: 14\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.2692 - accuracy: 0.9180\n",
      "Running model: 15\n",
      "116/116 [==============================] - 0s 819us/step - loss: 0.2265 - accuracy: 0.9180\n",
      "Running model: 16\n",
      "116/116 [==============================] - 0s 979us/step - loss: 0.2296 - accuracy: 0.9264\n",
      "Running model: 17\n",
      "116/116 [==============================] - 0s 935us/step - loss: 0.2022 - accuracy: 0.9304\n",
      "Running model: 18\n",
      "116/116 [==============================] - 0s 993us/step - loss: 0.2128 - accuracy: 0.9264\n",
      "Running model: 19\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.2320 - accuracy: 0.9215\n"
     ]
    }
   ],
   "source": [
    "models = tuner.get_best_models(10)\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    print('Running model:', i+10)\n",
    "    model.fit(x_train, y_train, epochs=param.values.get('tuner/epochs'), callbacks=[stop_early], validation_data=(x_val, y_val), verbose=0)\n",
    "    hyper_df = evaluate_model(model, x_test, y_test)\n",
    "    hyper_df.index = [\"Hypertuned-\" + str(i+10)]\n",
    "    # hyper_df['params'] = str(param.values)\n",
    "    # Append results in dataframe\n",
    "    results = pd.concat([results, hyper_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline</th>\n",
       "      <td>0.272868</td>\n",
       "      <td>0.896346</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hypertuned-0</th>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.921245</td>\n",
       "      <td>{'units': 128, 'activation': 'relu', 'num_laye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hypertuned-1</th>\n",
       "      <td>0.245964</td>\n",
       "      <td>0.920162</td>\n",
       "      <td>{'units': 480, 'activation': 'relu', 'num_laye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hypertuned-2</th>\n",
       "      <td>0.218396</td>\n",
       "      <td>0.923139</td>\n",
       "      <td>{'units': 384, 'activation': 'relu', 'num_laye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hypertuned-3</th>\n",
       "      <td>0.228288</td>\n",
       "      <td>0.913126</td>\n",
       "      <td>{'units': 192, 'activation': 'relu', 'num_laye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hypertuned-4</th>\n",
       "      <td>0.239683</td>\n",
       "      <td>0.908254</td>\n",
       "      <td>{'units': 320, 'activation': 'sigmoid', 'num_l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hypertuned-5</th>\n",
       "      <td>0.231724</td>\n",
       "      <td>0.913667</td>\n",
       "      <td>{'units': 128, 'activation': 'relu', 'num_laye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hypertuned-6</th>\n",
       "      <td>0.212580</td>\n",
       "      <td>0.923681</td>\n",
       "      <td>{'units': 480, 'activation': 'relu', 'num_laye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hypertuned-7</th>\n",
       "      <td>0.239480</td>\n",
       "      <td>0.910419</td>\n",
       "      <td>{'units': 480, 'activation': 'relu', 'num_laye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hypertuned-8</th>\n",
       "      <td>0.255425</td>\n",
       "      <td>0.912585</td>\n",
       "      <td>{'units': 480, 'activation': 'relu', 'num_laye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hypertuned-9</th>\n",
       "      <td>0.245501</td>\n",
       "      <td>0.906631</td>\n",
       "      <td>{'units': 384, 'activation': 'relu', 'num_laye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hypertuned-10</th>\n",
       "      <td>0.208298</td>\n",
       "      <td>0.930717</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hypertuned-11</th>\n",
       "      <td>0.310029</td>\n",
       "      <td>0.905007</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hypertuned-12</th>\n",
       "      <td>0.232016</td>\n",
       "      <td>0.924222</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hypertuned-13</th>\n",
       "      <td>0.250361</td>\n",
       "      <td>0.906631</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hypertuned-14</th>\n",
       "      <td>0.269153</td>\n",
       "      <td>0.917997</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hypertuned-15</th>\n",
       "      <td>0.226462</td>\n",
       "      <td>0.917997</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hypertuned-16</th>\n",
       "      <td>0.229593</td>\n",
       "      <td>0.926387</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hypertuned-17</th>\n",
       "      <td>0.202153</td>\n",
       "      <td>0.930447</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hypertuned-18</th>\n",
       "      <td>0.212802</td>\n",
       "      <td>0.926387</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hypertuned-19</th>\n",
       "      <td>0.231981</td>\n",
       "      <td>0.921516</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   loss  accuracy  \\\n",
       "Baseline       0.272868  0.896346   \n",
       "Hypertuned-0   0.227273  0.921245   \n",
       "Hypertuned-1   0.245964  0.920162   \n",
       "Hypertuned-2   0.218396  0.923139   \n",
       "Hypertuned-3   0.228288  0.913126   \n",
       "Hypertuned-4   0.239683  0.908254   \n",
       "Hypertuned-5   0.231724  0.913667   \n",
       "Hypertuned-6   0.212580  0.923681   \n",
       "Hypertuned-7   0.239480  0.910419   \n",
       "Hypertuned-8   0.255425  0.912585   \n",
       "Hypertuned-9   0.245501  0.906631   \n",
       "Hypertuned-10  0.208298  0.930717   \n",
       "Hypertuned-11  0.310029  0.905007   \n",
       "Hypertuned-12  0.232016  0.924222   \n",
       "Hypertuned-13  0.250361  0.906631   \n",
       "Hypertuned-14  0.269153  0.917997   \n",
       "Hypertuned-15  0.226462  0.917997   \n",
       "Hypertuned-16  0.229593  0.926387   \n",
       "Hypertuned-17  0.202153  0.930447   \n",
       "Hypertuned-18  0.212802  0.926387   \n",
       "Hypertuned-19  0.231981  0.921516   \n",
       "\n",
       "                                                          params  \n",
       "Baseline                                                     NaN  \n",
       "Hypertuned-0   {'units': 128, 'activation': 'relu', 'num_laye...  \n",
       "Hypertuned-1   {'units': 480, 'activation': 'relu', 'num_laye...  \n",
       "Hypertuned-2   {'units': 384, 'activation': 'relu', 'num_laye...  \n",
       "Hypertuned-3   {'units': 192, 'activation': 'relu', 'num_laye...  \n",
       "Hypertuned-4   {'units': 320, 'activation': 'sigmoid', 'num_l...  \n",
       "Hypertuned-5   {'units': 128, 'activation': 'relu', 'num_laye...  \n",
       "Hypertuned-6   {'units': 480, 'activation': 'relu', 'num_laye...  \n",
       "Hypertuned-7   {'units': 480, 'activation': 'relu', 'num_laye...  \n",
       "Hypertuned-8   {'units': 480, 'activation': 'relu', 'num_laye...  \n",
       "Hypertuned-9   {'units': 384, 'activation': 'relu', 'num_laye...  \n",
       "Hypertuned-10                                                NaN  \n",
       "Hypertuned-11                                                NaN  \n",
       "Hypertuned-12                                                NaN  \n",
       "Hypertuned-13                                                NaN  \n",
       "Hypertuned-14                                                NaN  \n",
       "Hypertuned-15                                                NaN  \n",
       "Hypertuned-16                                                NaN  \n",
       "Hypertuned-17                                                NaN  \n",
       "Hypertuned-18                                                NaN  \n",
       "Hypertuned-19                                                NaN  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BC1alHF5eB8O",
    "outputId": "d9e402f6-9bb0-4750-9d8e-5b7601aabefc"
   },
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, callbacks=callbacks, epochs=25, validation_data=(x_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "79Nz0yC4VJbB",
    "outputId": "a0dcd300-8286-4c51-9b09-35d52e5a695a"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model: You should evaluate the performance of the model\n",
    "# on the test set and compare it to the training set performance to determine\n",
    "# if the model has overfitted or underfitted the data.\n",
    "loss, acc = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(\"loss: %.2f\" % loss)\n",
    "print(\"acc: %.2f\" % acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kybz036JgNCk",
    "outputId": "8f6d8894-798b-4c02-bf96-e1c06063f229"
   },
   "outputs": [],
   "source": [
    "r = model.predict(x_test)\n",
    "# res = []\n",
    "# tmp = []\n",
    "# for i in range(24):\n",
    "#   if i%3 ==0 and i !=0:\n",
    "#     res.append(tmp)\n",
    "#     tmp = []\n",
    "#   tmp.append(r[i])\n",
    "# res.append(tmp)\n",
    "# res\n",
    "res = [np.argmax(i) for i in r]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eRk_8iFZJ-aZ",
    "outputId": "63e94a8d-0d76-49a5-f626-b1a5a86d272f"
   },
   "outputs": [],
   "source": [
    "model.save('./out/model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oyBVpYHwRpTq"
   },
   "outputs": [],
   "source": [
    "# Convert to TFLite model\n",
    "import tensorflow as tf\n",
    "\n",
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(\n",
    "    './out/model')  # path to the SavedModel directory\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open('model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4L3AKuKUToe_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.9 ('python310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "5104b67bda0624ec86c6ec05a8fc6d65bebceb8d1c1341c67a38cf3c49f6d320"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
