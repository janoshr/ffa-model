{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kCbo6EpgcVUF"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FCWvExeil5A1",
    "outputId": "af01cf44-138b-422b-89ac-8337b52cd9e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18471, 69)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/processed_data.csv')\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2DwofjBGV5Vu",
    "outputId": "def35a07-d36e-4cdb-a49a-1b2113313adb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final labels\n",
    "labels = ['patientState_good', 'patientState_caution', 'patientState_danger']\n",
    "# Section labels\n",
    "section_labels = {\n",
    "    'fever': ['feverState_good', 'feverState_caution', 'feverState_danger'],\n",
    "    'medication': ['medicationState_good', 'medicationState_caution', 'medicationState_danger'],\n",
    "    'hydration': ['hydrationState_good', 'hydrationState_caution', 'hydrationState_danger'],\n",
    "    'respiration': ['respirationState_good', 'respirationState_caution', 'respirationState_danger'],\n",
    "    'skin': ['skinState_good', 'skinState_caution', 'skinState_danger'],\n",
    "    'pulse': ['pulseState_good', 'pulseState_caution', 'pulseState_danger'],\n",
    "    'general': ['generalState_good', 'generalState_caution', 'generalState_danger'],\n",
    "}\n",
    "# Section labels in an array flattened\n",
    "section_labels_arr = [item for val in section_labels.values() for item in val]\n",
    "# All labels\n",
    "all_labels = [*labels, *section_labels_arr]\n",
    "len(all_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SxKJ2bSyYk2B",
    "outputId": "43ed643c-308c-4e14-e0d4-522226ffd95b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generalState_good  generalState_caution  generalState_danger\n",
       "1.0                0.0                   0.0                    10142\n",
       "0.0                1.0                   0.0                     7976\n",
       "                   0.0                   1.0                      353\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[section_labels['general']].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mWqUV0NUat2j",
    "outputId": "be460c23-5c6c-4b7d-ea1d-72254c667811"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11082, 45)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separating to testing and training\n",
    "\n",
    "# Prepare the data: You should split your data into training and test sets.\n",
    "# The training set will be used to train the model and the test set will be used\n",
    "# to evaluate the model's performance.\n",
    "\n",
    "_x, x_test, _y, y_test = train_test_split(\n",
    "    df.drop(columns=all_labels).to_numpy(),\n",
    "    df[labels].to_numpy(),\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    _x,\n",
    "    _y,\n",
    "    test_size=0.25,\n",
    "    train_size=0.75,\n",
    "    random_state=42\n",
    ")\n",
    "x_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "omaRfxh9ozLC",
    "outputId": "1dcde71f-213f-4563-8982-e7315c181532"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[15.6173706445342, 1.0, 38.3, 0.0, 0.0, 0.0, 1.0, 1.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 13.0, 0.0, 0.0, 0.0, 0.0, 68.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(list(x_test[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "UBWlLfXBUf6u"
   },
   "outputs": [],
   "source": [
    "# Preprocess the data: Data preprocessing is an important step, which includes\n",
    "# cleaning and transforming the data. You should normalize the data,\n",
    "# one-hot encode categorical variables, and split the data into features and labels.\n",
    "\n",
    "# TODO: Does KNNImputer create a correlation between training and test split?\n",
    "# If yes do ->\n",
    "# TODO: move KNNImputer here\n",
    "# TODO: move every preprocessing step that would create a connection between train and test split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 45)                2070      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 138       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,208\n",
      "Trainable params: 2,208\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-25 16:04:28.734411: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-02-25 16:04:28.734510: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# Create a baseline model to measure performance\n",
    "b_model = keras.Sequential([\n",
    "    keras.layers.Dense(units=45, activation='tanh', input_shape=(45,)),\n",
    "    keras.layers.Dense(units=3, activation='softmax'),\n",
    "])\n",
    "b_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "b_model.build()\n",
    "b_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-25 16:04:28.983892: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-02-25 16:04:29.130242: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-25 16:04:31.415671: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "347/347 - 3s - loss: 0.7544 - accuracy: 0.6608 - val_loss: 0.6614 - val_accuracy: 0.7044 - 3s/epoch - 9ms/step\n",
      "Epoch 2/20\n",
      "347/347 - 3s - loss: 0.6018 - accuracy: 0.7712 - val_loss: 0.5533 - val_accuracy: 0.7975 - 3s/epoch - 8ms/step\n",
      "Epoch 3/20\n",
      "347/347 - 3s - loss: 0.5187 - accuracy: 0.8079 - val_loss: 0.4975 - val_accuracy: 0.8059 - 3s/epoch - 8ms/step\n",
      "Epoch 4/20\n",
      "347/347 - 3s - loss: 0.4709 - accuracy: 0.8252 - val_loss: 0.4654 - val_accuracy: 0.8249 - 3s/epoch - 8ms/step\n",
      "Epoch 5/20\n",
      "347/347 - 3s - loss: 0.4436 - accuracy: 0.8319 - val_loss: 0.4485 - val_accuracy: 0.8170 - 3s/epoch - 8ms/step\n",
      "Epoch 6/20\n",
      "347/347 - 3s - loss: 0.4191 - accuracy: 0.8396 - val_loss: 0.4235 - val_accuracy: 0.8368 - 3s/epoch - 8ms/step\n",
      "Epoch 7/20\n",
      "347/347 - 3s - loss: 0.4075 - accuracy: 0.8429 - val_loss: 0.4158 - val_accuracy: 0.8414 - 3s/epoch - 8ms/step\n",
      "Epoch 8/20\n",
      "347/347 - 3s - loss: 0.3925 - accuracy: 0.8466 - val_loss: 0.3979 - val_accuracy: 0.8457 - 3s/epoch - 9ms/step\n",
      "Epoch 9/20\n",
      "347/347 - 3s - loss: 0.3816 - accuracy: 0.8540 - val_loss: 0.4015 - val_accuracy: 0.8468 - 3s/epoch - 8ms/step\n",
      "Epoch 10/20\n",
      "347/347 - 3s - loss: 0.3723 - accuracy: 0.8557 - val_loss: 0.3818 - val_accuracy: 0.8495 - 3s/epoch - 8ms/step\n",
      "Epoch 11/20\n",
      "347/347 - 3s - loss: 0.3637 - accuracy: 0.8583 - val_loss: 0.3740 - val_accuracy: 0.8549 - 3s/epoch - 8ms/step\n",
      "Epoch 12/20\n",
      "347/347 - 3s - loss: 0.3556 - accuracy: 0.8626 - val_loss: 0.3662 - val_accuracy: 0.8609 - 3s/epoch - 8ms/step\n",
      "Epoch 13/20\n",
      "347/347 - 3s - loss: 0.3464 - accuracy: 0.8645 - val_loss: 0.3659 - val_accuracy: 0.8479 - 3s/epoch - 8ms/step\n",
      "Epoch 14/20\n",
      "347/347 - 3s - loss: 0.3449 - accuracy: 0.8648 - val_loss: 0.3634 - val_accuracy: 0.8576 - 3s/epoch - 9ms/step\n",
      "Epoch 15/20\n",
      "347/347 - 3s - loss: 0.3361 - accuracy: 0.8680 - val_loss: 0.3535 - val_accuracy: 0.8641 - 3s/epoch - 8ms/step\n",
      "Epoch 16/20\n",
      "347/347 - 3s - loss: 0.3309 - accuracy: 0.8738 - val_loss: 0.3438 - val_accuracy: 0.8665 - 3s/epoch - 8ms/step\n",
      "Epoch 17/20\n",
      "347/347 - 3s - loss: 0.3244 - accuracy: 0.8748 - val_loss: 0.3430 - val_accuracy: 0.8663 - 3s/epoch - 8ms/step\n",
      "Epoch 18/20\n",
      "347/347 - 3s - loss: 0.3222 - accuracy: 0.8753 - val_loss: 0.3613 - val_accuracy: 0.8576 - 3s/epoch - 8ms/step\n",
      "Epoch 19/20\n",
      "347/347 - 3s - loss: 0.3217 - accuracy: 0.8737 - val_loss: 0.3426 - val_accuracy: 0.8628 - 3s/epoch - 8ms/step\n",
      "Epoch 20/20\n",
      "347/347 - 3s - loss: 0.3138 - accuracy: 0.8811 - val_loss: 0.3306 - val_accuracy: 0.8722 - 3s/epoch - 8ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28c20ba90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train baseline model\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "# Early stopping set after 5 epochs\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "b_model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=[stop_early],\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3167 - accuracy: 0.8788\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline</th>\n",
       "      <td>0.316732</td>\n",
       "      <td>0.878755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              loss  accuracy\n",
       "Baseline  0.316732  0.878755"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate_model(model, x_test, y_test):\n",
    "    \"\"\"\n",
    "    evaluate model on test set and show results in dataframe.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : keras model\n",
    "        trained keras model.\n",
    "    X_test : numpy array\n",
    "        Features of holdout set.\n",
    "    y_test : numpy array\n",
    "        Labels of holdout set.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    display_df : DataFrame\n",
    "        Pandas dataframe containing evaluation results.\n",
    "    \"\"\"\n",
    "    eval_dict = model.evaluate(x_test, y_test, return_dict=True)\n",
    "    \n",
    "    display_df = pd.DataFrame([eval_dict.values()], columns=[list(eval_dict.keys())])\n",
    "    \n",
    "    return display_df\n",
    "\n",
    "# Evaluate model on test set and add results to dataframe\n",
    "results = evaluate_model(b_model, x_test, y_test)\n",
    "\n",
    "# Set index to 'Baseline'\n",
    "results.index = ['Baseline']\n",
    "\n",
    "# Display results\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "95i1CiBhU2CL",
    "outputId": "d74a9d05-6a5a-4ef8-f5c8-3c80af36128d"
   },
   "outputs": [],
   "source": [
    "# Define the model: TensorFlow provides a high-level API for building and\n",
    "# training neural network models. You should choose the appropriate model\n",
    "# architecture for your problem and specify the hyperparameters,\n",
    "# such as the number of hidden layers and the number of neurons in each layer.\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='./checkpoints/model_{epoch}',\n",
    "        save_freq='epoch'),\n",
    "    keras.callbacks.TensorBoard(log_dir='./logs')\n",
    "]\n",
    "\n",
    "\n",
    "def build_model(hp):\n",
    "    \"\"\"\n",
    "    Builds model and sets up hyperparameter space to search.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    hp : HyperParameter object\n",
    "        Configures hyperparameters to tune.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    model : keras model\n",
    "        Compiled model with hyperparameters to tune.\n",
    "    \"\"\"\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(\n",
    "            units=hp.Int('units', min_value=32, max_value=512, step=32),\n",
    "            activation=hp.Choice('activation', values=['tanh', 'sigmoid', 'relu']),\n",
    "            input_shape=(45,)),\n",
    "    ])\n",
    "    # Tune the number of hidden layers and units in each.\n",
    "    # Number of hidden layers: 1 - 4\n",
    "    # Number of Units: 32 - 512 with stepsize of 32\n",
    "    num_layers = hp.Int(\"num_layers\", 2, 5)\n",
    "    for i in range(1, num_layers):\n",
    "        with hp.conditional_scope('num_layers', list(range(i+1, 5+1))):\n",
    "            model.add(\n",
    "                keras.layers.Dense(\n",
    "                    units=hp.Int(\"units_\" + str(i), min_value=32, max_value=512, step=32),\n",
    "                    activation=hp.Choice('activation_' + str(i), values=['tanh', 'sigmoid', 'relu']),\n",
    "                )\n",
    "            )\n",
    "            # Tune dropout layer with values from 0 - 0.3 with stepsize of 0.1.\n",
    "            model.add(keras.layers.Dropout(hp.Float(\"dropout_\" + str(i), 0, 0.3, step=0.1)))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(\n",
    "        keras.layers.Dense(3, activation='softmax')\n",
    "    )\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
    "        # optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    model.build()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "vvetSq2eVARF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project tuner3/hyperband/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from tuner3/hyperband/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "# Compile the model: You should compile the model by specifying the optimizer,\n",
    "# loss function, and evaluation metrics.\n",
    "import keras_tuner\n",
    "\n",
    "tuner = keras_tuner.tuners.Hyperband(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    executions_per_trial=2,\n",
    "    hyperband_iterations=2,\n",
    "    max_epochs=100,\n",
    "    factor=3,\n",
    "    overwrite=False,\n",
    "    directory='tuner3',\n",
    "    project_name=\"hyperband\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 240 Complete [00h 01m 44s]\n",
      "val_loss: 0.6574364900588989\n",
      "\n",
      "Best val_loss So Far: 0.21755419671535492\n",
      "Total elapsed time: 00h 05m 03s\n",
      "\n",
      "Search: Running Trial #241\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "96                |256               |units\n",
      "tanh              |sigmoid           |activation\n",
      "5                 |3                 |num_layers\n",
      "320               |256               |units_1\n",
      "sigmoid           |relu              |activation_1\n",
      "0.2               |0.1               |dropout_1\n",
      "0.0001            |0.001             |learning_rate\n",
      "256               |416               |units_2\n",
      "sigmoid           |sigmoid           |activation_2\n",
      "0.2               |0.1               |dropout_2\n",
      "384               |None              |units_3\n",
      "tanh              |None              |activation_3\n",
      "0                 |None              |dropout_3\n",
      "384               |None              |units_4\n",
      "relu              |None              |activation_4\n",
      "0.2               |None              |dropout_4\n",
      "34                |34                |tuner/epochs\n",
      "0                 |0                 |tuner/initial_epoch\n",
      "1                 |1                 |tuner/bracket\n",
      "0                 |0                 |tuner/round\n",
      "\n",
      "Epoch 1/34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-25 16:10:30.124446: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "347/347 [==============================] - ETA: 0s - loss: 0.8150 - accuracy: 0.6624"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-25 16:10:35.167672: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "347/347 [==============================] - 6s 17ms/step - loss: 0.8150 - accuracy: 0.6624 - val_loss: 0.7519 - val_accuracy: 0.6600\n",
      "Epoch 2/34\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.7174 - accuracy: 0.6803 - val_loss: 0.6668 - val_accuracy: 0.7293\n",
      "Epoch 3/34\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.6427 - accuracy: 0.7364 - val_loss: 0.5941 - val_accuracy: 0.7699\n",
      "Epoch 4/34\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.5673 - accuracy: 0.7790 - val_loss: 0.5465 - val_accuracy: 0.7799\n",
      "Epoch 5/34\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.5295 - accuracy: 0.7895 - val_loss: 0.5095 - val_accuracy: 0.7937\n",
      "Epoch 6/34\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.4962 - accuracy: 0.8064 - val_loss: 0.4852 - val_accuracy: 0.8116\n",
      "Epoch 7/34\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.4802 - accuracy: 0.8136 - val_loss: 0.4986 - val_accuracy: 0.7953\n",
      "Epoch 8/34\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.4721 - accuracy: 0.8147 - val_loss: 0.4974 - val_accuracy: 0.7972\n",
      "Epoch 9/34\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.4534 - accuracy: 0.8213 - val_loss: 0.4790 - val_accuracy: 0.8059\n",
      "Epoch 10/34\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.4498 - accuracy: 0.8233 - val_loss: 0.4572 - val_accuracy: 0.8189\n",
      "Epoch 11/34\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.4383 - accuracy: 0.8262 - val_loss: 0.4798 - val_accuracy: 0.8078\n",
      "Epoch 12/34\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.4353 - accuracy: 0.8278 - val_loss: 0.4336 - val_accuracy: 0.8265\n",
      "Epoch 13/34\n",
      "347/347 [==============================] - 5s 14ms/step - loss: 0.4284 - accuracy: 0.8297 - val_loss: 0.4362 - val_accuracy: 0.8267\n",
      "Epoch 14/34\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.4273 - accuracy: 0.8292 - val_loss: 0.4241 - val_accuracy: 0.8313\n",
      "Epoch 15/34\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.4198 - accuracy: 0.8326 - val_loss: 0.4383 - val_accuracy: 0.8311\n",
      "Epoch 16/34\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.4166 - accuracy: 0.8344 - val_loss: 0.4377 - val_accuracy: 0.8300\n",
      "Epoch 17/34\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.4178 - accuracy: 0.8367 - val_loss: 0.4204 - val_accuracy: 0.8378\n",
      "Epoch 18/34\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.4135 - accuracy: 0.8384 - val_loss: 0.4731 - val_accuracy: 0.8192\n",
      "Epoch 19/34\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.4061 - accuracy: 0.8398 - val_loss: 0.4213 - val_accuracy: 0.8311\n",
      "Epoch 20/34\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.4029 - accuracy: 0.8408 - val_loss: 0.4226 - val_accuracy: 0.8297\n",
      "Epoch 21/34\n",
      "347/347 [==============================] - 5s 14ms/step - loss: 0.3971 - accuracy: 0.8425 - val_loss: 0.4183 - val_accuracy: 0.8362\n",
      "Epoch 22/34\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.3936 - accuracy: 0.8428 - val_loss: 0.4209 - val_accuracy: 0.8384\n",
      "Epoch 23/34\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.3891 - accuracy: 0.8471 - val_loss: 0.4406 - val_accuracy: 0.8322\n",
      "Epoch 24/34\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.3880 - accuracy: 0.8481 - val_loss: 0.3976 - val_accuracy: 0.8462\n",
      "Epoch 25/34\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.3818 - accuracy: 0.8498 - val_loss: 0.4112 - val_accuracy: 0.8454\n",
      "Epoch 26/34\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.3805 - accuracy: 0.8505 - val_loss: 0.4185 - val_accuracy: 0.8411\n",
      "Epoch 27/34\n",
      "347/347 [==============================] - 5s 14ms/step - loss: 0.3748 - accuracy: 0.8537 - val_loss: 0.3869 - val_accuracy: 0.8462\n",
      "Epoch 28/34\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.3711 - accuracy: 0.8539 - val_loss: 0.4112 - val_accuracy: 0.8284\n",
      "Epoch 29/34\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.3636 - accuracy: 0.8574 - val_loss: 0.3850 - val_accuracy: 0.8519\n",
      "Epoch 30/34\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.3643 - accuracy: 0.8574 - val_loss: 0.3810 - val_accuracy: 0.8508\n",
      "Epoch 31/34\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.3605 - accuracy: 0.8581 - val_loss: 0.3921 - val_accuracy: 0.8357\n",
      "Epoch 32/34\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.3491 - accuracy: 0.8626 - val_loss: 0.3825 - val_accuracy: 0.8517\n",
      "Epoch 33/34\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.3506 - accuracy: 0.8600 - val_loss: 0.3936 - val_accuracy: 0.8503\n",
      "Epoch 34/34\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.3479 - accuracy: 0.8649 - val_loss: 0.3753 - val_accuracy: 0.8546\n",
      "Epoch 1/34\n",
      "  1/347 [..............................] - ETA: 1:55 - loss: 1.1049 - accuracy: 0.3125"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-25 16:13:09.062839: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "347/347 [==============================] - ETA: 0s - loss: 0.8161 - accuracy: 0.6626"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-25 16:13:13.200942: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "347/347 [==============================] - 5s 14ms/step - loss: 0.8161 - accuracy: 0.6626 - val_loss: 0.7373 - val_accuracy: 0.6724\n",
      "Epoch 2/34\n",
      "157/347 [============>.................] - ETA: 41s - loss: 0.7489 - accuracy: 0.6636"
     ]
    }
   ],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "tuner.search(x_train, y_train, validation_data=(x_val, y_val), epochs=4, callbacks=[stop_early])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tuner.results_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search_space_summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best val_loss So Far: 0.3011022210121155\n",
    "\n",
    "- 5 epochs\n",
    "- 512 units\n",
    "- tanh activation\n",
    "- True 2nd layer\n",
    "- 0.001 learning_rate\n",
    "- 192 units2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = tuner.get_best_hyperparameters(10)\n",
    "\n",
    "for i, param in enumerate(params):\n",
    "    print('Running model:', i)\n",
    "    model = tuner.hypermodel.build(param)\n",
    "    model.fit(x_train, y_train, epochs=param.values.get('tuner/epochs'), callbacks=callbacks, validation_data=(x_val, y_val))\n",
    "    hyper_df = evaluate_model(model, x_test, y_test)\n",
    "    hyper_df.index = [\"Hypertuned-\" + str(i)]\n",
    "    hyper_df['units'] = param.values.get('units')\n",
    "    hyper_df['activation'] = param.values.get('activation')\n",
    "    hyper_df['learning_rate'] = param.values.get('learning_rate')\n",
    "    hyper_df['epochs'] = param.values.get('tuner/epochs')\n",
    "    hyper_df['2nd_layer'] = param.values.get('2nd_layer')\n",
    "    hyper_df['units2'] = param.values.get('units2')\n",
    "    # Append results in dataframe\n",
    "    results = pd.concat([results, hyper_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 1: 116/116 [==============================] - 3s 24ms/step - loss: 0.2007 - accuracy: 0.9369\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BC1alHF5eB8O",
    "outputId": "d9e402f6-9bb0-4750-9d8e-5b7601aabefc"
   },
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, callbacks=callbacks, epochs=25, validation_data=(x_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "79Nz0yC4VJbB",
    "outputId": "a0dcd300-8286-4c51-9b09-35d52e5a695a"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model: You should evaluate the performance of the model\n",
    "# on the test set and compare it to the training set performance to determine\n",
    "# if the model has overfitted or underfitted the data.\n",
    "loss, acc = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(\"loss: %.2f\" % loss)\n",
    "print(\"acc: %.2f\" % acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kybz036JgNCk",
    "outputId": "8f6d8894-798b-4c02-bf96-e1c06063f229"
   },
   "outputs": [],
   "source": [
    "r = model.predict(x_test)\n",
    "# res = []\n",
    "# tmp = []\n",
    "# for i in range(24):\n",
    "#   if i%3 ==0 and i !=0:\n",
    "#     res.append(tmp)\n",
    "#     tmp = []\n",
    "#   tmp.append(r[i])\n",
    "# res.append(tmp)\n",
    "# res\n",
    "res = [np.argmax(i) for i in r]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eRk_8iFZJ-aZ",
    "outputId": "63e94a8d-0d76-49a5-f626-b1a5a86d272f"
   },
   "outputs": [],
   "source": [
    "model.save('./out/model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oyBVpYHwRpTq"
   },
   "outputs": [],
   "source": [
    "# Convert to TFLite model\n",
    "import tensorflow as tf\n",
    "\n",
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(\n",
    "    './out/model')  # path to the SavedModel directory\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open('model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4L3AKuKUToe_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
